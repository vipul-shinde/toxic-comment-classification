[![forthebadge](https://forthebadge.com/images/badges/made-with-python.svg)](https://forthebadge.com)
[![forthebadge](images/powered-by-aws.svg)](https://forthebadge.com)
[![forthebadge](images/made-with-flask.svg)](https://forthebadge.com)

<h1 align="center">Toxic Comment Classification using Flask & AWS 🔍</h1>

<div align="center">

  [![Status](https://img.shields.io/badge/status-active-success.svg)]()
  [![Open Source Love png1](https://badges.frapsoft.com/os/v1/open-source.png?v=103)]()
  [![GitHub license](https://img.shields.io/github/license/Naereen/StrapDown.js.svg)]()

</div>

---

<p align="center"> This is a toxic comment classifier web application that uses a Logistic Regression model to predict the toxicity levels of a given text input.
Link to the web app: 👉🏻 http://ec2-18-117-78-151.us-east-2.compute.amazonaws.com:8080/
</p>

<h2> Link to the web app: 👉🏻 http://ec2-18-117-78-151.us-east-2.compute.amazonaws.com:8080/</h2>

# toxic-comment-classification
Toxic Comment Classifier Web App using Flask and AWS

# AWS link

http://ec2-18-117-78-151.us-east-2.compute.amazonaws.com:8080/