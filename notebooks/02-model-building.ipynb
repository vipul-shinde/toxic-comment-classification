{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing the Libraries\nimport pandas as pd\nimport numpy as np\nimport re, string\nimport swifter\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words(\"english\"))\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.pipeline import FeatureUnion, Pipeline\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, roc_auc_score\nfrom sklearn.linear_model import LogisticRegression\nfrom scipy.sparse import hstack\nimport joblib\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-02-02T19:13:41.802513Z","iopub.execute_input":"2022-02-02T19:13:41.802805Z","iopub.status.idle":"2022-02-02T19:13:41.811113Z","shell.execute_reply.started":"2022-02-02T19:13:41.802774Z","shell.execute_reply":"2022-02-02T19:13:41.810255Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Importing the training dataset\ntrain_df = pd.read_csv(\"../input/toxic-data/train.csv\")\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-02T18:53:37.642389Z","iopub.execute_input":"2022-02-02T18:53:37.642613Z","iopub.status.idle":"2022-02-02T18:53:39.598579Z","shell.execute_reply.started":"2022-02-02T18:53:37.642587Z","shell.execute_reply":"2022-02-02T18:53:39.597713Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                 id                                       comment_text  toxic  \\\n0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n\n   severe_toxic  obscene  threat  insult  identity_hate  \n0             0        0       0       0              0  \n1             0        0       0       0              0  \n2             0        0       0       0              0  \n3             0        0       0       0              0  \n4             0        0       0       0              0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Importing the test data\ntest_data = pd.read_csv(\"../input/toxic-data/test.csv\")\ntest_labels = pd.read_csv(\"../input/toxic-data/test_labels.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-02-02T18:53:39.600949Z","iopub.execute_input":"2022-02-02T18:53:39.601669Z","iopub.status.idle":"2022-02-02T18:53:41.388588Z","shell.execute_reply.started":"2022-02-02T18:53:39.601622Z","shell.execute_reply":"2022-02-02T18:53:41.387702Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Merging the two datasets above for complete test data\ntest_df = pd.merge(test_data, test_labels, on=\"id\")\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-02T18:53:41.390002Z","iopub.execute_input":"2022-02-02T18:53:41.390240Z","iopub.status.idle":"2022-02-02T18:53:41.552412Z","shell.execute_reply.started":"2022-02-02T18:53:41.390211Z","shell.execute_reply":"2022-02-02T18:53:41.551638Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                 id                                       comment_text  toxic  \\\n0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...     -1   \n1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...     -1   \n2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...     -1   \n3  00017563c3f7919a  :If you have a look back at the source, the in...     -1   \n4  00017695ad8997eb          I don't anonymously edit articles at all.     -1   \n\n   severe_toxic  obscene  threat  insult  identity_hate  \n0            -1       -1      -1      -1             -1  \n1            -1       -1      -1      -1             -1  \n2            -1       -1      -1      -1             -1  \n3            -1       -1      -1      -1             -1  \n4            -1       -1      -1      -1             -1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00001cee341fdb12</td>\n      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0000247867823ef7</td>\n      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00013b17ad220c46</td>\n      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00017563c3f7919a</td>\n      <td>:If you have a look back at the source, the in...</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00017695ad8997eb</td>\n      <td>I don't anonymously edit articles at all.</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Filtering out the samples having actual target labels\nnew_test_df = test_df[(test_df['toxic']!=-1) & (test_df['severe_toxic']!=-1) & (test_df['obscene']!=-1) & \n             (test_df['threat']!=-1) & (test_df['insult']!=-1) & (test_df['identity_hate']!=-1)]\nnew_test_df.reset_index(drop=True, inplace=True)\nnew_test_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-02T18:53:41.553639Z","iopub.execute_input":"2022-02-02T18:53:41.553980Z","iopub.status.idle":"2022-02-02T18:53:41.579262Z","shell.execute_reply.started":"2022-02-02T18:53:41.553937Z","shell.execute_reply":"2022-02-02T18:53:41.578456Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                 id                                       comment_text  toxic  \\\n0  0001ea8717f6de06  Thank you for understanding. I think very high...      0   \n1  000247e83dcc1211                   :Dear god this site is horrible.      0   \n2  0002f87b16116a7f  \"::: Somebody will invariably try to add Relig...      0   \n3  0003e1cccfd5a40a  \" \\n\\n It says it right there that it IS a typ...      0   \n4  00059ace3e3e9a53  \" \\n\\n == Before adding a new product to the l...      0   \n\n   severe_toxic  obscene  threat  insult  identity_hate  \n0             0        0       0       0              0  \n1             0        0       0       0              0  \n2             0        0       0       0              0  \n3             0        0       0       0              0  \n4             0        0       0       0              0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0001ea8717f6de06</td>\n      <td>Thank you for understanding. I think very high...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000247e83dcc1211</td>\n      <td>:Dear god this site is horrible.</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0002f87b16116a7f</td>\n      <td>\"::: Somebody will invariably try to add Relig...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0003e1cccfd5a40a</td>\n      <td>\" \\n\\n It says it right there that it IS a typ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00059ace3e3e9a53</td>\n      <td>\" \\n\\n == Before adding a new product to the l...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Creating a function to clean the training dataset\ndef clean_text(text):\n    \"\"\"This function will take text as input and return a cleaned text \n        by removing html char, punctuations, non-letters, newline and converting it \n        to lower case.\n    \"\"\"\n    # Converting to lower case letters\n    text = text.lower()\n    # Removing the contraction of few words\n    text = re.sub(r\"what's\", \"what is \", text)\n    text = re.sub(r\"\\'s\", \" \", text)\n    text = re.sub(r\"\\'ve\", \" have \", text)\n    text = re.sub(r\"can't\", \"can not \", text)\n    text = re.sub(r\"n't\", \" not \", text)\n    text = re.sub(r\"i'm\", \"i am \", text)\n    text = re.sub(r\"\\'re\", \" are \", text)\n    text = re.sub(r\"\\'d\", \" would \", text)\n    text = re.sub(r\"\\'ll\", \" will \", text)\n    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n    # Replacing the HTMl characters with \" \"\n    text = re.sub(\"<.*?>\", \" \", text)\n    # Removing the punctuations\n    text = text.translate(str.maketrans(\" \", \" \", string.punctuation))\n    # Removing non-letters\n    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n    # Replacing newline with space\n    text = re.sub(\"\\n\", \" \", text)\n    # Split on space and rejoin to remove extra spaces\n    text = \" \".join(text.split())\n    \n    return text","metadata":{"execution":{"iopub.status.busy":"2022-02-02T18:53:41.580389Z","iopub.execute_input":"2022-02-02T18:53:41.581089Z","iopub.status.idle":"2022-02-02T18:53:41.591805Z","shell.execute_reply.started":"2022-02-02T18:53:41.581043Z","shell.execute_reply":"2022-02-02T18:53:41.591255Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def word_lemmatizer(text):\n    \"\"\"This function will help lemmatize words in a text.\n    \"\"\"\n    \n    lemmatizer = WordNetLemmatizer()\n    # Tokenize the sentences to words\n    text = word_tokenize(text)\n    # Removing the stop words\n    text = [lemmatizer.lemmatize(word) for word in text]\n    # Joining the cleaned list\n    text = \" \".join(text)\n    \n    return text","metadata":{"execution":{"iopub.status.busy":"2022-02-02T18:53:41.593085Z","iopub.execute_input":"2022-02-02T18:53:41.595140Z","iopub.status.idle":"2022-02-02T18:53:41.606581Z","shell.execute_reply.started":"2022-02-02T18:53:41.595094Z","shell.execute_reply":"2022-02-02T18:53:41.605957Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Cleaning and preprocessing the train data\ntrain_df[\"comment_text\"] = train_df[\"comment_text\"].swifter.apply(clean_text)\ntrain_df[\"comment_text\"] = train_df[\"comment_text\"].swifter.apply(word_lemmatizer)\n\n# Cleaning and preprocessing the test data\nnew_test_df[\"comment_text\"] = new_test_df[\"comment_text\"].swifter.apply(clean_text)\nnew_test_df[\"comment_text\"] = new_test_df[\"comment_text\"].swifter.apply(word_lemmatizer)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T18:53:41.607890Z","iopub.execute_input":"2022-02-02T18:53:41.608349Z","iopub.status.idle":"2022-02-02T18:57:58.321144Z","shell.execute_reply.started":"2022-02-02T18:53:41.608301Z","shell.execute_reply":"2022-02-02T18:57:58.320468Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Pandas Apply:   0%|          | 0/159571 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3619f3a29cea44dba245917008789347"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Pandas Apply:   0%|          | 0/159571 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"052aacc226524e8cbbbcdfc54cbd7e52"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Pandas Apply:   0%|          | 0/63978 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec9007aaae214fa7befdc0394d4343ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Pandas Apply:   0%|          | 0/63978 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2536462adb842ea94923462c7fd41ce"}},"metadata":{}}]},{"cell_type":"code","source":"# Performing the train-val split to create training and validation datasets\ntrain, validation = train_test_split(train_df, test_size=0.2, random_state=42)\n# print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\nprint(train.shape, validation.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T19:01:02.591580Z","iopub.execute_input":"2022-02-02T19:01:02.592152Z","iopub.status.idle":"2022-02-02T19:01:02.642754Z","shell.execute_reply.started":"2022-02-02T19:01:02.592104Z","shell.execute_reply":"2022-02-02T19:01:02.641740Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"(127656, 8) (31915, 8)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Seperating our input and target variable columns\nX_train = train.comment_text\nX_val = validation.comment_text\nX_test = new_test_df.comment_text","metadata":{"execution":{"iopub.status.busy":"2022-02-02T19:01:03.573120Z","iopub.execute_input":"2022-02-02T19:01:03.573584Z","iopub.status.idle":"2022-02-02T19:01:03.579363Z","shell.execute_reply.started":"2022-02-02T19:01:03.573537Z","shell.execute_reply":"2022-02-02T19:01:03.578543Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Storing our target labels list in a variable\nlabels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']","metadata":{"execution":{"iopub.status.busy":"2022-02-02T19:01:05.455223Z","iopub.execute_input":"2022-02-02T19:01:05.456119Z","iopub.status.idle":"2022-02-02T19:01:05.460715Z","shell.execute_reply.started":"2022-02-02T19:01:05.456071Z","shell.execute_reply":"2022-02-02T19:01:05.460138Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Creating a unigram TFIDF vectorizer and transforming all our input features\nword_tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 1), sublinear_tf=True, strip_accents=\"unicode\", \n                             analyzer=\"word\",token_pattern=r\"\\w{1,}\", stop_words=stop_words)\n\nword_tfidf.fit(train_df.comment_text)\n\ntrain_word_tfidf = word_tfidf.transform(X_train)\nval_word_tfidf = word_tfidf.transform(X_val)\ntest_word_tfidf = word_tfidf.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T19:01:49.453128Z","iopub.execute_input":"2022-02-02T19:01:49.453578Z","iopub.status.idle":"2022-02-02T19:02:12.765172Z","shell.execute_reply.started":"2022-02-02T19:01:49.453530Z","shell.execute_reply":"2022-02-02T19:02:12.764066Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Creating a n-gram (2, 6) TFIDF vectorizer and transforming all our input features\nchar_tfidf = TfidfVectorizer(max_features=30000, ngram_range=(2, 6), sublinear_tf=True, strip_accents=\"unicode\", \n                             analyzer=\"char\", stop_words=stop_words)\n\nchar_tfidf.fit(train_df.comment_text)\n\ntrain_char_tfidf = char_tfidf.transform(X_train)\nval_char_tfidf = char_tfidf.transform(X_val)\ntest_char_tfidf = char_tfidf.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T19:02:12.767116Z","iopub.execute_input":"2022-02-02T19:02:12.767441Z","iopub.status.idle":"2022-02-02T19:11:40.807533Z","shell.execute_reply.started":"2022-02-02T19:02:12.767407Z","shell.execute_reply":"2022-02-02T19:11:40.806836Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Concatenating both unigram and n-gram features for our training input\ntrain_features = hstack([train_word_tfidf, train_char_tfidf])\nval_features = hstack([val_word_tfidf, val_char_tfidf])\ntest_features = hstack([test_word_tfidf, test_char_tfidf])","metadata":{"execution":{"iopub.status.busy":"2022-02-02T19:11:40.808636Z","iopub.execute_input":"2022-02-02T19:11:40.808871Z","iopub.status.idle":"2022-02-02T19:11:44.779986Z","shell.execute_reply.started":"2022-02-02T19:11:40.808833Z","shell.execute_reply":"2022-02-02T19:11:44.779191Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Saving the tfidf vectors for future use\njoblib.dump(word_tfidf, \"word_tfidf_vectorizer.pkl\")\njoblib.dump(char_tfidf, \"char_tfidf_vectorizer.pkl\")","metadata":{"execution":{"iopub.status.busy":"2022-02-02T19:54:27.471405Z","iopub.execute_input":"2022-02-02T19:54:27.471978Z","iopub.status.idle":"2022-02-02T19:54:48.067089Z","shell.execute_reply.started":"2022-02-02T19:54:27.471928Z","shell.execute_reply":"2022-02-02T19:54:48.066221Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"['char_tfidf_vectorizer.pkl']"},"metadata":{}}]},{"cell_type":"code","source":"# Creating a logistic regression Model and treating each target as a binary classification problem\nlr_model = OneVsRestClassifier(LogisticRegression(solver=\"saga\"))\nval_results = {\"Accuracy\": {}, \"F1 Score\": {}}\ntest_results = {\"Accuracy\": {}, \"F1 Score\": {}}\n\nfor label in labels:\n    print(f\"... Processing {label}\")\n    # train the model using X & y\n    lr_model.fit(train_features, train[label])\n    # Predicting the validation data labels\n    val_prediction = lr_model.predict(val_features)\n    # Predicting the test data labels\n    test_prediction = lr_model.predict(test_features)\n    # Saving the model based on target label\n    joblib.dump(lr_model, f\"logistic_regression_{label}.pkl\")\n    # Checking and model's accuracy and f1-score\n    val_results[\"Accuracy\"][f\"{label}\"] = accuracy_score(validation[label], val_prediction)\n    val_results[\"F1 Score\"][f\"{label}\"] = f1_score(validation[label], val_prediction, average = \"weighted\")\n    test_results[\"Accuracy\"][f\"{label}\"] = accuracy_score(new_test_df[label], test_prediction)\n    test_results[\"F1 Score\"][f\"{label}\"] = f1_score(new_test_df[label], test_prediction, average = \"weighted\")","metadata":{"execution":{"iopub.status.busy":"2022-02-02T20:06:19.396172Z","iopub.execute_input":"2022-02-02T20:06:19.396454Z","iopub.status.idle":"2022-02-02T20:21:38.113603Z","shell.execute_reply.started":"2022-02-02T20:06:19.396426Z","shell.execute_reply":"2022-02-02T20:21:38.112640Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"... Processing toxic\n... Processing severe_toxic\n... Processing obscene\n... Processing threat\n... Processing insult\n... Processing identity_hate\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluating the model on Validation Data\nvalidation_accuracy = sum(val_results[\"Accuracy\"].values())/len(val_results[\"Accuracy\"])\nprint(f\"Validation Accuracy: {validation_accuracy}\")\n\nvalidation_f1_score = sum(val_results[\"F1 Score\"].values())/len(val_results[\"F1 Score\"])\nprint(f\"Validation F1-Score: {validation_f1_score}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-02T20:31:58.075788Z","iopub.execute_input":"2022-02-02T20:31:58.076062Z","iopub.status.idle":"2022-02-02T20:31:58.081668Z","shell.execute_reply.started":"2022-02-02T20:31:58.076029Z","shell.execute_reply":"2022-02-02T20:31:58.080838Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"Validation Accuracy: 0.9828502793879577\nValidation F1-Score: 0.9811947440446507\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluating the model on Test Data\ntest_accuracy = sum(test_results[\"Accuracy\"].values())/len(test_results[\"Accuracy\"])\nprint(f\"Validation Accuracy: {test_accuracy}\")\n\ntest_f1_score = sum(test_results[\"F1 Score\"].values())/len(test_results[\"F1 Score\"])\nprint(f\"Validation F1-Score: {test_f1_score}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-02T20:31:21.727127Z","iopub.execute_input":"2022-02-02T20:31:21.728003Z","iopub.status.idle":"2022-02-02T20:31:21.735586Z","shell.execute_reply.started":"2022-02-02T20:31:21.727944Z","shell.execute_reply":"2022-02-02T20:31:21.734756Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"Validation Accuracy: 0.9752805651942854\nValidation F1-Score: 0.9747181660736461\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}